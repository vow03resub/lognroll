#!/usr/bin/python
#-*- coding: utf-8 -*-

import os
import re
import ast
import sys
import copy
import time
import uuid
import argparse
import pickle
from random import randint
from collections import defaultdict

prepopulated_log_templates = [
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree .* for container\-id .*: .* of .* physical memory used; .* of .* virtual memory used",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: .* Container Transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=.* IP=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event .* for appId .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:.*, vCores:.*> numContainers=.* user=.* user-resources=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=.* usedCapacity=.* absoluteUsedCapacity=.* used=<memory:.*, vCores:.*> cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re\-sorting assigned queue: root.default stats: default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing .* from application .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: .* in state: .* event:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container .* is : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt .* released container .* on node: host: .* #containers=.* available=<memory:.*, vCores:.*> used=<memory:.*, vCores:.*> with event: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re\-sorting completed queue: root.default stats: default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container .* of capacity <memory:.*, vCores:.*> on host .*, which has .* containers, <memory:.*, vCores:.*> used and <memory:.*, vCores:.*> available after allocation",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container .* of capacity <memory:.*, vCores:.*> on host .*, which currently has .* containers, <memory:.*, vCores:.*> used and <memory:.*, vCores:.*> available, release resources=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=.* container=Container: \[ContainerId: .*, NodeId: .*, NodeHttpAddress: .*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: .*, \] queue=default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.* clusterResource=<memory:.*, vCores:.*> type=.* requestedPartition=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: \[ContainerId: .*, NodeId: .*, NodeHttpAddress: .*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .* }, \] queue=default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.* cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding .* to application .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got .* for service .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Neither virutal\-memory nor physical\-memory monitoring is needed. Not running the monitor\-thread",
"INFO org.apache.hadoop.mapred.ShuffleHandler: Setting connection close header\.\.\.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=.* usedCapacity=.* absoluteUsedCapacity=.* used=<memory:.*, vCores:.*> cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: \[.*\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed containers from NM context: \[.*\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for .* by user .*",
"INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for .* \(auth:.*\)",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Application .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: .* State change from .* to .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling .* file .* for deletion",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: .*:.* src: .* dest: .*",
"INFO org.apache.hadoop.ipc.Server: IPC Server listener on .*: starting",
"INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class .* queueCapacity: .*",
"INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class .* for class .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted .* .* file .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: .*:.*, type=.*, downstreams=.*:\[.*\] terminating",
"INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in .* msecs",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state",
"INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with .* entries .* lookups",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :\[.*\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from .* to .*",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: .* metrics system started",
"INFO org.apache.hadoop.util.GSet: VM type = .*",
"INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts \(include/exclude\) list",
"INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties",
"INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode extension entered.",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode is OFF",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* UnderReplicatedBlocks has .* blocks",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for .*",
"INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port .*",
"INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = .*",
"INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules",
"INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating .* at .*:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application .* requests cleared",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree : .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin : .*",
"INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter\(org.mortbay.log\) via org.mortbay.log.Slf4jLog",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: .* and ContainerTokenKeyActivationDelay: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: .* and NMTokenKeyActivationDelay: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : .*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: .*",
"INFO org.apache.hadoop.yarn.webapp.WebApps: Web app .* started at .*",
"WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node .*:.* clusterResource: <memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol .* to the server",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at .* second\(s\).",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container .* succeeded",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: .* = .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /.*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /.*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /.*:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in .* seconds.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger :.* txns",
"INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: .* = .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to .* = file:.*",
"INFO org.apache.hadoop.http.HttpServer2: Added filter .* \(class=.*\) to context .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: .*:.*, type=.* terminating",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at .*/.*:.*",
"INFO org.apache.hadoop.yarn.util.RackResolver: Resolved .* to /default\-rack",
"INFO org.mortbay.log: Extract jar:file:.*\!.*",
"INFO org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet: dr.who is accessing unchecked .* which is the app master GUI of .* owned by .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up",
"INFO org.apache.hadoop.util.GSet: capacity = .* = .* entries",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file .* size .* bytes.",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took .*s at .* KB/s",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Perms after creating .*, Expected: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to .*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid .*",
"INFO BlockStateChange: BLOCK\* addToInvalidates: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: .* State change from .* to .* on event=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file .*\. Credentials list:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, \".*\"",
"INFO org.apache.hadoop.util.GSet: Computing capacity for map .*",
"INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port .*",
"INFO org.apache.hadoop.http.HttpServer2: Added global filter '.*' \(class=.*\)",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.*",
"WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Slow BlockReceiver write data to disk cost:.*ms \(threshold=.*ms\)",
"INFO org.apache.hadoop.util.GSet: .*% max memory .* = .*",
"INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http\.requests\..* is not defined",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: .* = .*",
"INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: .* = .*",
"INFO org.apache.hadoop.http.HttpServer2: adding path spec: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to .*/.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: .*:.* Node Transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out .* NM container statuses: \[.*\]",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to .* milliseconds",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file .* using no compression",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool .* on volume .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on .* acquired by nodename .*",
"INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application .* from user: .*, in queue: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for .* is undefined",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application .* from user: .* activated in queue: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /.*:.*, dest: /.*:.*, bytes: .*, op: .*, cliID: .*, offset: .*, srvID: .*, blockid: .*:.*, duration: .*",
"INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize .*, falling back to use random secrets.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : .*:.* for container : .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around .*",
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* allocate .*{UCState=.*, truncateBlock=.*, primaryNodeIndex=.*, replicas=\[ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\].*\]} for .*",
"INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for .* at: http:.*:.*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval .* milliseconds",
"INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume \- .*, StorageType: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading .* expecting start txid #.*",
"INFO BlockStateChange: BLOCK\* addStoredBlock: blockMap updated: .*:.* is added to .*{UCState=.*, truncateBlock=.*, primaryNodeIndex=.*, replicas=\[ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\]\]} size .*",
"INFO org.apache.hadoop.yarn.webapp.View: Getting list of all Jobs.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=.*, fullname=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id .*",
"INFO org.apache.hadoop.hdfs.StateChange: DIR\* completeFile: .* is closed by .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: .*",
"INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at .*/.*:.*",
"INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is .* bytes/s",
"INFO org.apache.hadoop.conf.Configuration: found resource .* at file:.*",
"INFO BlockStateChange: BLOCK\* addStoredBlock: blockMap updated: .*:.* is added to .* size .*",
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* registerDatanode: from DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*\) storage .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool .* on volume .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool .*: .*ms",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file .* of size .* bytes saved in .* seconds.",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as .*:.* with total resource of <memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container\-requests as container manager rpc server is still starting.",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: .*, with delay of .* seconds",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: .*: numChildQueue= .*, capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>usedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: History Cleaner .*",
"INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: .* unregistered successfully.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...",
"INFO org.mortbay.log: jetty-6.1.26",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=.*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=.*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=.*",
"INFO .*: STARTUP_MSG:",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id .* submitted by user .*",
"INFO .*: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from .* to .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Using .* threads to upgrade data directories \(dfs.datanode.parallel.volumes.load.threads.num=.*, dataDirs=.*\)",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: .*ms",
"INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain .* images with txid >= .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for .* is undefined",
"ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value below .* ms/sec. Assuming default value of .*",
"INFO BlockStateChange: BLOCK\* BlockManager: ask .*:.* to delete \[.*\]",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled",
"INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min\(s\)",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: .* sent to absent container .*",
"INFO org.mortbay.log: Started HttpServer2\$SelectChannelConnectorWithSafeStartup@.*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : file:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode ON.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading .* INodes.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager\$ApplicationSummary: appId=.*,name=.*,user=.*,queue=.*,state=.*,trackingUrl=http:.*,appMasterHost=.*,startTime=.*,finishTime=.*,finalStatus=.*,memorySeconds=.*,vcoreSeconds=.*,preemptedAMContainers=.*,preemptedNonAMContainers=.*,preemptedResources=<memory:.*, vCores:.*>,applicationType=.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at .*ms with interval of .*ms",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid .* to namenode at http://.*:.* in .* seconds",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt .* with final state: .*, and exit status: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt .* to scheduler from user .* in queue .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool .* \(Datanode Uuid .*\) service to .*/.*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = .*", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt .* is done. finalState=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: .*ms and AMRMTokenKeyActivationDelay: .* ms",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> \(Datanode Uuid unassigned\) service to .*/.*:.* starting to offer service",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file .* of size .* edits # .* loaded in .* seconds",
"INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine \(eg GC\): pause of approximately .*ms",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added \- appId: .* user: .* leaf-queue of parent: root #applications: .*",
"WARN org.apache.hadoop.hdfs.server.common.Util: Path .* should be specified as a URI in configuration files. Please update hdfs configuration.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node .*\(cmPort: .* httpPort: .*\) registered with capability: <memory:.*, vCores:.*>, assigned nodeId .*:.*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Replication Queue initialization scan for invalid, over\- and under\-replicated blocks completed in .* msec",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID .* for DN .*:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast\-forwarding stream '.*' to transaction ID .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid .* from .*",
"INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command .* is: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application .* with final state: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean", ##
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled\? .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled\? .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://.*:.*",
"INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/\*",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=.*;bpid=.*;lv=.*;nsInfo=.*;cid=.*;nsid=.*;c=.*;bpid=.*;dnuuid=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period :.* secs \(.* min\)",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for .*: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile\(file=.*, cpktTxId=.*\)",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed \- appId: .* user: .* queue: .* #user-pending-applications: .* #user-active-applications: .* #queue-pending-applications: .* #queue-active-applications: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: JobHistory Init",
"INFO org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage: CachedHistoryStorage Init",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode \[.*\]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool .* \(Datanode Uuid .*\) service to .*/.*:.* trying to claim ACTIVE state with txid=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use .* of total heap and retry cache entry expiry time is .* millis",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool .* on volume .*: .*ms",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode .*/.*:.* using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: .*msec; heartBeatInterval=.*", ##
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* fsync: .* for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile\(file=.*, cpktTxId=.*\)",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from .* to .* for .*",
"INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from .* stream\(s\).",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: .*, capacity=.*, asboluteCapacity=.*, maxCapacity=.*, asboluteMaxCapacity=.*, state=.*, acls=.*:.*:.*, labels=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: .* Total time for transactions\(ms\): .* Number of transactions batched in Syncs: .* Number of syncs: .* SyncTimes\(ms\): .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=4", ##
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Leaving safe mode after .* secs",
"INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner\(.*, .*\): no suitable block pools found to scan. Waiting .* ms.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= .*, capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>usedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool .* \(Datanode Uuid null\) service to .*/.*:.* beginning handshake with NN",
"INFO BlockStateChange: BLOCK\* processReport .*: from storage .* node DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*;cid=.*;nsid=.*;c=.*\), blocks: .*, hasStaleStorage: .*, processing time: .* msecs",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report .*, containing .* storage report\(s\), of which we sent .*\. The reports had .* total blocks and used .* RPC\(s\)\. This took .* msec to generate and .* msecs for RPC and NN processing. Got back one command: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image\? .* \(staleImage=.*, haEnabled=.*, isRollingUpgrade=.*\)",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use .*:.* to access this namenode/service.",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Network topology has .* racks and .* datanodes",
"INFO BlockStateChange: BLOCK\* ask .*:.* to replicate .* to datanode\(s\) .*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool .* on .*: .*ms",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named '.*' in the configuration is for class .* which has a name of '.*'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool .* \(Datanode Uuid null\) service to .*/.*:.* successfully registered with NN",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container .* : .*",
"INFO org.apache.hadoop.http.HttpServer2: Added filter '.*' \(class=.*\)",
"INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file .* \-> .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: .*: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.*}, ] for AM .*",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with .* G physical memory allocated to containers, which is more than .*% of the total physical memory available \(.* G\). Thrashing might happen.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added \- appId: .* user: .*, leaf\-queue: .* #user-pending-applications: .* #user-active-applications: .* #queue-pending-applications: .* #queue-active-applications: .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryClientService: Instantiated HistoryClientService at .*/.*:.*",
"INFO org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system \[hdfs://.*:.*\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed \- appId: .* user: .* leaf\-queue of parent: .* #applications: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in .*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode ON, in safe mode extension.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class .*, minimumAllocation=<<memory:.*, vCores:.*>>, maximumAllocation=<<memory:.*, vCores:.*>>, asynchronousScheduling=.*, asyncScheduleInterval=.*ms",
"WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory \(dfs.namenode.name.dir\) configured. Beware of data loss due to lack of redundant storage directories!",
"WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory \(dfs.namenode.edits.dir\) configured. Beware of data loss due to lack of redundant storage directories!",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.* }, \] for AM .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: .* AttemptId: .* MasterContainer: Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.* }, \]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting CheckDiskError Thread",
"INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Initializing Existing Jobs\.\.\.",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: \[hdfs:.*\]",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://.* to hdfs://.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool .* Total blocks: .*, missing metadata files:.*, missing block files:.*, missing blocks in memory:.*, mismatched blocks:.*",
"INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=.*,submitTime=.*,launchTime=.*,firstMapTaskLaunchTime=.*,firstReduceTaskLaunchTime=.*,finishTime=.*,resourcesPerMap=.*,resourcesPerReduce=.*,numMaps=.*,numReduces=.*,user=.*,queue=.*,status=.*,mapSlotSeconds=.*,reduceSlotSeconds=.*,jobName=.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: .*:.*:DataXceiver error processing WRITE_BLOCK operation src: .* dst: .*; org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block .* already exists in state .* and thus cannot be created.",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Explicitly setting permissions to : .*, .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock .*:.* received exception org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block .*:.* already exists in state .* and thus cannot be created.",
"WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*;cid=.*;nsid=.*;c=.*\):Failed to transfer .*:.* to .*:.* got",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*;cid=.*;nsid=.*;c=.*\) Starting thread to transfer .*:.* to .*:.*",
]

prepopulated_log_templates = [
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree .* for container\-id .*: .* of .* physical memory used; .* of .* virtual memory used",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: .* Container Transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.*",
#"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
#"INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=.* IP=.* OPERATION=.* Container Request TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event .* for appId .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:.*, vCores:.*> numContainers=.* user=.* user\-resources=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=.* usedCapacity=.* absoluteUsedCapacity=.* used=<memory:.*, vCores:.*> cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re\-sorting assigned queue: .* stats: default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing .* from application .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: .* in state: .* event:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for .*",
"WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container .* is : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt .* released container .* on node: host: .* #containers=.* available=<memory:.*, vCores:.*> used=<memory:.*, vCores:.*> with event: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re\-sorting completed queue: root.default stats: default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container .* of capacity <memory:.*, vCores:.*> on host .*:.*, which has .* containers, <memory:.*, vCores:.*> used and <memory:.*, vCores:.*> available after allocation",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container .* of capacity <memory:.*, vCores:.*> on host .*:.*, which currently has .* containers, <memory:.*, vCores:.*> used and <memory:.*, vCores:.*> available, release resources=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=.* container=Container: \[ContainerId: .*, NodeId: .*, NodeHttpAddress: .*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: .*, \] queue=default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.* clusterResource=<memory:.*, vCores:.*> type=.* requestedPartition=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: \[ContainerId: .*, NodeId: .*, NodeHttpAddress: .*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .* }, \] queue=default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.* cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding .* to application .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got .* for service .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Neither virutal\-memory nor physical\-memory monitoring is needed. Not running the monitor\-thread",
"INFO org.apache.hadoop.mapred.ShuffleHandler: Setting connection close header\.\.\.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=.* usedCapacity=.* absoluteUsedCapacity=.* used=<memory:.*, vCores:.*> cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: \[nice, \-n, .*, bash, .*\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed containers from NM context: \[.*\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for .* by user .*",
"INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for .* \(auth:SIMPLE\)",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Application .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: .* State change from .* to .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling .* file .* for deletion",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: .*:.* src: .* dest: .*",
"INFO org.apache.hadoop.ipc.Server: IPC Server listener on .*: starting",
"INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class .* queueCapacity: .*",
"INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class .* for class .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted .* .* file .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: .*:.*, type=.*, downstreams=.*:\[.*\] terminating",
"INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in .* msecs",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state",
"INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with .* entries .* lookups",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :\[.*\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from .* to .*",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: .* metrics system started",
"INFO org.apache.hadoop.util.GSet: VM type = .*",
"INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts \(include/exclude\) list",
"INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties",
"INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode extension entered.",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode is OFF",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* UnderReplicatedBlocks has .* blocks",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for .*",
"INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port .*",
"INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = .*",
"INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules",
"INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating .* at .*:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application .* requests cleared",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree : .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin : .*",
"INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter\(org.mortbay.log\) via org.mortbay.log.Slf4jLog",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: .* and ContainerTokenKeyActivationDelay: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: .* and NMTokenKeyActivationDelay: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : .*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: .*",
"INFO org.apache.hadoop.yarn.webapp.WebApps: Web app .* started at .*",
"WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node .*:.* clusterResource: <memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol .* to the server",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at .* second\(s\).",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container .* succeeded",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: .* = .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /.*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /.*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /.*:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in .* seconds.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger :.* txns",
"INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: .* = .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to .* = file:.*",
"INFO org.apache.hadoop.http.HttpServer2: Added filter .* \(class=.*\) to context .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: .*:.*, type=.* terminating",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at .*/.*:.*",
"INFO org.apache.hadoop.yarn.util.RackResolver: Resolved .* to /default\-rack",
"INFO org.mortbay.log: Extract jar:file:.*\!.*",
"INFO org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet: dr.who is accessing unchecked .* which is the app master GUI of .* owned by .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up",
"INFO org.apache.hadoop.util.GSet: capacity = .* = .* entries",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file .* size .* bytes.",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took .*s at .* KB/s",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Perms after creating .*, Expected: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to .*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid .*",
"INFO BlockStateChange: BLOCK\* addToInvalidates: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: .* State change from .* to .* on event=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file .*\. Credentials list:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, \".*\"",
"INFO org.apache.hadoop.util.GSet: Computing capacity for map .*",
"INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port .*",
"INFO org.apache.hadoop.http.HttpServer2: Added global filter '.*' \(class=.*\)",

#"INFO .*: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for \[TERM, HUP, INT\]",

"WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Slow BlockReceiver write data to disk cost:.*ms \(threshold=.*ms\)",
"INFO org.apache.hadoop.util.GSet: .*% max memory .* = .*",
"INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http\.requests\..* is not defined",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: .* = .*",
"INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: .* = .*",
"INFO org.apache.hadoop.http.HttpServer2: adding path spec: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to .*/.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: .*:.* Node Transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out .* NM container statuses: \[.*\]",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to .* milliseconds",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file .* using no compression",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool .* on volume .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on .* acquired by nodename .*",
"INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application .* from user: .*, in queue: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for .* is undefined",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application .* from user: .* activated in queue: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /.*:.*, dest: /.*:.*, bytes: .*, op: .*, cliID: .*, offset: .*, srvID: .*, blockid: .*:.*, duration: .*",
"INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize .*, falling back to use random secrets.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : .*:.* for container : .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around .*",
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* allocate .*{UCState=.*, truncateBlock=.*, primaryNodeIndex=.*, replicas=\[ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\].*\]} for .*",
"INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for .* at: http:.*:.*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval .* milliseconds",
"INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume \- .*, StorageType: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading .* expecting start txid #.*",
"INFO BlockStateChange: BLOCK\* addStoredBlock: blockMap updated: .*:.* is added to .*{UCState=.*, truncateBlock=.*, primaryNodeIndex=.*, replicas=\[ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\], ReplicaUC\[\[DISK\].*:.*:.*:.*\|.*\]\]} size .*",
"INFO org.apache.hadoop.yarn.webapp.View: Getting list of all Jobs.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=.*, fullname=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id .*",
"INFO org.apache.hadoop.hdfs.StateChange: DIR\* completeFile: .* is closed by .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: .*",
"INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at .*/.*:.*",
"INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is .* bytes/s",
"INFO org.apache.hadoop.conf.Configuration: found resource .* at file:.*",
"INFO BlockStateChange: BLOCK\* addStoredBlock: blockMap updated: .*:.* is added to .* size .*",
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* registerDatanode: from DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*\) storage .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool .* on volume .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool .*: .*ms",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file .* of size .* bytes saved in .* seconds.",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as .*:.* with total resource of <memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container\-requests as container manager rpc server is still starting.",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: .*, with delay of .* seconds",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: .*: numChildQueue= .*, capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>usedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: History Cleaner .*",
"INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: .* unregistered successfully.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...",
"INFO org.mortbay.log: jetty-6.1.26",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=.*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=.*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=.*",

#"INFO .*: STARTUP_MSG:",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG:",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: STARTUP_MSG:",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG:",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG:",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:",

"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id .* submitted by user .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from .* to .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Using .* threads to upgrade data directories \(dfs.datanode.parallel.volumes.load.threads.num=.*, dataDirs=.*\)",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: .*ms",
"INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain .* images with txid >= .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for .* is undefined",
"ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value below .* ms/sec. Assuming default value of .*",
"INFO BlockStateChange: BLOCK\* BlockManager: ask .*:.* to delete \[.*\]",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled",
"INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min\(s\)",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: .* sent to absent container .*",
"INFO org.mortbay.log: Started HttpServer2\$SelectChannelConnectorWithSafeStartup@.*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : file:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode ON.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading .* INodes.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager\$ApplicationSummary: appId=.*,name=.*,user=.*,queue=.*,state=.*,trackingUrl=http:.*,appMasterHost=.*,startTime=.*,finishTime=.*,finalStatus=.*,memorySeconds=.*,vcoreSeconds=.*,preemptedAMContainers=.*,preemptedNonAMContainers=.*,preemptedResources=<memory:.*, vCores:.*>,applicationType=.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at .*ms with interval of .*ms",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid .* to namenode at http://.*:.* in .* seconds",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt .* with final state: .*, and exit status: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt .* to scheduler from user .* in queue .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool .* \(Datanode Uuid .*\) service to .*/.*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = .*", ##
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt .* is done. finalState=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: .*ms and AMRMTokenKeyActivationDelay: .* ms",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> \(Datanode Uuid unassigned\) service to .*/.*:.* starting to offer service",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file .* of size .* edits # .* loaded in .* seconds",
"INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine \(eg GC\): pause of approximately .*ms",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added \- appId: .* user: .* leaf-queue of parent: root #applications: .*",
"WARN org.apache.hadoop.hdfs.server.common.Util: Path .* should be specified as a URI in configuration files. Please update hdfs configuration.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node .*\(cmPort: .* httpPort: .*\) registered with capability: <memory:.*, vCores:.*>, assigned nodeId .*:.*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Replication Queue initialization scan for invalid, over\- and under\-replicated blocks completed in .* msec",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID .* for DN .*:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast\-forwarding stream '.*' to transaction ID .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid .* from .*",
"INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command .* is: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application .* with final state: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean", ##
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled\? .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled\? .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://.*:.*",
"INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/\*",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=.*;bpid=.*;lv=.*;nsInfo=.*;cid=.*;nsid=.*;c=.*;bpid=.*;dnuuid=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period :.* secs \(.* min\)",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for .*: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile\(file=.*, cpktTxId=.*\)",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed \- appId: .* user: .* queue: .* #user-pending-applications: .* #user-active-applications: .* #queue-pending-applications: .* #queue-active-applications: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: JobHistory Init",
"INFO org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage: CachedHistoryStorage Init",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode \[.*\]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool .* \(Datanode Uuid .*\) service to .*/.*:.* trying to claim ACTIVE state with txid=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use .* of total heap and retry cache entry expiry time is .* millis",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool .* on volume .*: .*ms",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode .*/.*:.* using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: .*msec; heartBeatInterval=.*", ##
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* fsync: .* for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile\(file=.*, cpktTxId=.*\)",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from .* to .* for .*",
"INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from .* stream\(s\).",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: .*, capacity=.*, asboluteCapacity=.*, maxCapacity=.*, asboluteMaxCapacity=.*, state=.*, acls=.*:.*:.*, labels=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: .* Total time for transactions\(ms\): .* Number of transactions batched in Syncs: .* Number of syncs: .* SyncTimes\(ms\): .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=4", ##
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Leaving safe mode after .* secs",
"INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner\(.*, .*\): no suitable block pools found to scan. Waiting .* ms.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= .*, capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>usedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool .* \(Datanode Uuid null\) service to .*/.*:.* beginning handshake with NN",
"INFO BlockStateChange: BLOCK\* processReport .*: from storage .* node DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*;cid=.*;nsid=.*;c=.*\), blocks: .*, hasStaleStorage: .*, processing time: .* msecs",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report .*, containing .* storage report\(s\), of which we sent .*\. The reports had .* total blocks and used .* RPC\(s\)\. This took .* msec to generate and .* msecs for RPC and NN processing. Got back one command: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image\? .* \(staleImage=.*, haEnabled=.*, isRollingUpgrade=.*\)",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use .*:.* to access this namenode/service.",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Network topology has .* racks and .* datanodes",
"INFO BlockStateChange: BLOCK\* ask .*:.* to replicate .* to datanode\(s\) .*:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool .* on .*: .*ms",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named '.*' in the configuration is for class .* which has a name of '.*'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool .* \(Datanode Uuid null\) service to .*/.*:.* successfully registered with NN",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container .* : .*",
"INFO org.apache.hadoop.http.HttpServer2: Added filter '.*' \(class=.*\)",
"INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file .* \-> .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: .*: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.*}, ] for AM .*",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with .* G physical memory allocated to containers, which is more than .*% of the total physical memory available \(.* G\). Thrashing might happen.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added \- appId: .* user: .*, leaf\-queue: .* #user-pending-applications: .* #user-active-applications: .* #queue-pending-applications: .* #queue-active-applications: .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryClientService: Instantiated HistoryClientService at .*/.*:.*",
"INFO org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system \[hdfs://.*:.*\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed \- appId: .* user: .* leaf\-queue of parent: .* #applications: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in .*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode ON, in safe mode extension.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class .*, minimumAllocation=<<memory:.*, vCores:.*>>, maximumAllocation=<<memory:.*, vCores:.*>>, asynchronousScheduling=.*, asyncScheduleInterval=.*ms",
"WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory \(dfs.namenode.name.dir\) configured. Beware of data loss due to lack of redundant storage directories!",
"WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory \(dfs.namenode.edits.dir\) configured. Beware of data loss due to lack of redundant storage directories!",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.* }, \] for AM .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: .* AttemptId: .* MasterContainer: Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.* }, \]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting CheckDiskError Thread",
"INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Initializing Existing Jobs\.\.\.",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: \[hdfs:.*\]",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://.* to hdfs://.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool .* Total blocks: .*, missing metadata files:.*, missing block files:.*, missing blocks in memory:.*, mismatched blocks:.*",
"INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=.*,submitTime=.*,launchTime=.*,firstMapTaskLaunchTime=.*,firstReduceTaskLaunchTime=.*,finishTime=.*,resourcesPerMap=.*,resourcesPerReduce=.*,numMaps=.*,numReduces=.*,user=.*,queue=.*,status=.*,mapSlotSeconds=.*,reduceSlotSeconds=.*,jobName=.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: .*:.*:DataXceiver error processing WRITE_BLOCK operation src: .* dst: .*; org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block .* already exists in state .* and thus cannot be created.",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Explicitly setting permissions to : .*, .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock .*:.* received exception org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block .*:.* already exists in state .* and thus cannot be created.",
"WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*;cid=.*;nsid=.*;c=.*\):Failed to transfer .*:.* to .*:.* got",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=.*;cid=.*;nsid=.*;c=.*\) Starting thread to transfer .*:.* to .*:.*",

]

def remove_log_template_matches(logs, logtem):
    # Remove matching logs using pre-filled log templates
    for i in range(0,len(logtem)):
        log_template = logtem[i]
        # Remove any matched logs from the logs.
        before_removal = len(logs)
        alog = None
        for j in reversed(range(0,len(logs))):
            matched = re.match("^"+log_template+"$",logs[j])
            if matched!=None:
                alog = logs[j]
                #print alog
                del logs[j]
        removed_logs = before_removal - len(logs)

        if removed_logs==0:
            print "ERROR: no matching logs found from the given template."
            print "template:", log_template
            sys.exit(0)

        print "\033[0;34m"+"["+format(i,'3d')+"]",format(len(logs),'5d'),format(removed_logs,'4d'),"\033[0m","\033[0;35m\""+logtem[i]+"\",\033[0m"

        #raw_input("\033[0;35m->Press ENTER to continue filtering ...\033[0m")


def read_a_logfile(infile):
    logs = []

    lines = [line.rstrip() for line in infile]
    for log in lines:
        if len(log.strip())==0:
            continue
        log = " ".join(log.split())
        logs.append(log)

    print "Total number of logs loaded:",len(logs)
    return logs


if __name__ == '__main__':

    global new_pattern_added

    try:
        parser = argparse.ArgumentParser(description="")
        parser.add_argument('--logfile', type=argparse.FileType('r'), required=True, help='One logfile name.')

        args = parser.parse_args()
        input_logfile = args.logfile

    except Exception, e:
        print('Error: %s' % str(e))

    print "Loading all logs into memory."
    raw_logs = read_a_logfile(input_logfile)

    loaded_log_count = len(raw_logs)
    remove_log_template_matches(raw_logs, prepopulated_log_templates)
    print "Loaded Log count:", loaded_log_count
    print "Remaining Log count:",len(raw_logs)
    print "Prepopulated log template count:", len(prepopulated_log_templates)

    
    if len(raw_logs)>0:
        loglen_d = defaultdict()
        for i in range(0,len(raw_logs)):
            log = raw_logs[i]
            loglen = len(log.split())

            if loglen not in loglen_d:
                loglen_d[loglen] = []
            loglen_d[loglen].append(log)

        for x in sorted(loglen_d, key=lambda k: len(loglen_d[k]), reverse=False):
            print "\033[31;35m Token_len=", x, "    # of logs:",len(loglen_d[x]), "\033[0m"

        most_popular = sorted(loglen_d, key=lambda k: len(loglen_d[k]), reverse=True)[0]
        print "most_popular=",most_popular
        print " "
        for x in sorted(loglen_d[most_popular])[:500]:
            print "\""+x+"\","


    print "\033[31;35mRemaining Log count:",len(raw_logs), "\033[0m"
    print "\033[31;36mNumber of log templates:",len(prepopulated_log_templates), "\033[0m"
    #pickle.dump(raw_logs,open("TMP1029348.bin","wb"))

    log_templates = []
    for t in prepopulated_log_templates:
        log_templates.append({"count":1,"template":t}) 
    pickle.dump(log_templates,open("TMP1029348.bin","wb"))
    print "TMP1029348.bin file written."
