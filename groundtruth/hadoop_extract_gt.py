#!/usr/bin/python
#-*- coding: utf-8 -*-

import os
import re
import ast
import sys
import copy
import time
import uuid
import argparse
import pickle
from random import randint
from collections import defaultdict

prepopulated_log_templates = [
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree .* for container\-id .*: .* of .* physical memory used; .* of .* virtual memory used",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: .* Container Transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event .* for appId .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for .* by user .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container .* of capacity <memory:.*, vCores:.*> on host .*, which has .* containers, <memory:.*, vCores:.*> used and <memory:.*, vCores:.*> available after allocation",
"INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for .* \(auth:.*\)",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container .* of capacity <memory:.*, vCores:.*> on host .*, which currently has .* containers, <memory:.*, vCores:.*> used and <memory:.*, vCores:.*> available, release resources=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt .* released container .* on node: host: .*:.* #containers=.* available=<memory:.*, vCores:.*> used=<memory:.*, vCores:.*> with event: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Neither virutal\-memory nor physical\-memory monitoring is needed. Not running the .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed containers from NM context: \[.*\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding .* to application .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource\-monitoring for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing .* from application .*",
"INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource\-monitoring for .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=.* IP=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=.* usedCapacity=.* absoluteUsedCapacity=.* used=<memory:.*, vCores:.*> cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol .* to the server",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got .* for service .*",
"INFO org.apache.hadoop.mapred.ShuffleHandler: Setting connection close .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=.* container=Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: null, \] queue=default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.* clusterResource=<memory:.*, vCores:.*> type=.* requestedPartition=",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: .* in state: .* event:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.* }, \] queue=default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.* cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re\-sorting completed queue: root.default stats: default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re\-sorting assigned queue: root.default stats: default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=.* usedCapacity=.* absoluteUsedCapacity=.* used=<memory:.*, vCores:.*> cluster=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* CONTAINERID=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource .* transitioned from .* to .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file .* Credentials list.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Application .* transitioned from .* to .*",
"WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container .* is : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:.*, vCores:.*> numContainers=.* user=.* user\-resources=<memory:.*, vCores:.*>",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: \[nice, \-n, .*, bash, .*\]",
"INFO org.apache.hadoop.ipc.Server: IPC Server listener on .*: starting",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling .* file .* for deletion",
"INFO org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet: .* is accessing unchecked .* which is the app master GUI of .* owned by .*",
"INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: .* State change from .* to .* on event=.*",
"INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: .* State change from .* to .*",
"INFO org.mortbay.log: jetty\-6.1.26",
"INFO org.mortbay.log: Extract jar:file:.*!.* to .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from .* to .*",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at .* second\(s\).",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to .* = file:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted .* .* file .*",
"INFO org.apache.hadoop.http.HttpServer2: Added filter .* \(class=.*\) to context .*",
"INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize .*, falling back to use random secrets.",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from .* to .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid .* from .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from .* to .* for .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: .*",
"INFO org.apache.hadoop.util.GSet: capacity = .* = .* entries",
"INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec .*",
"INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from .* stream\(s\).",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = .*",
"INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests..* is not defined",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool .* on volume .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool .*: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for .*: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out .* NM container statuses: \[\]",
"INFO org.apache.hadoop.util.GSet: Computing capacity for map .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in .* seconds.",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took .* at .*",
"INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command .* is: .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks = .*",
"INFO org.apache.hadoop.yarn.webapp.WebApps: Web app .* started at .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving .*:.* src: /.* dest: /.*",
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* allocate .*{UCState=.*, truncateBlock=.*, primaryNodeIndex=.*, replicas=.*} for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt .* is done. finalState=.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application .* with final state: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: .*:.*, type=.*, downstreams=.*:\[\] terminating",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: .*:.* Node Transitioned from .* to .*",
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* fsync: .* for .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving .* to .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: .*",
"INFO org.apache.hadoop.util.GSet: .* max memory .* = .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around .* .* .* .*:.*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file .* using no compression",
"INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class .* for class .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container\-requests",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading .* expecting start txid #.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree : .*",
"INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume \- .*, StorageType: DISK",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt .* to scheduler from user .* in queue .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:.*",
"INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' \(class=org.apache.hadoop.http.HttpServer2\$QuotingInputFilter\)",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in .* msecs",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* UnderReplicatedBlocks has .* blocks",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of over\-replicated blocks = .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added \- appId: .* user: .* leaf\-queue of parent: .* #applications: .*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Leaving safe mode after .* secs",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool .* \(Datanode Uuid .*\) service to .*/155.230.91.226:.*",
"INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file .* of size .* bytes saved in .* seconds.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use .* of total heap and retry cache entry expiry time is .* millis",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image\? .* \(staleImage=.*, haEnabled=.*, isRollingUpgrade=.*\)",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool .* \(Datanode Uuid .*\) service to .* trying to claim .* state with txid=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id .* submitted by user .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical\-memory=.* virtual\-memory=.* virtual\-cores=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report .*, containing .* storage report\(s\), of which we sent .*. The reports had .* total blocks and used .* RPC\(s\). This took .* msec to generate and .* msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to .* milliseconds",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is .* bytes/s",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files",
"INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with .* entries .* lookups",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool .* \(Datanode Uuid null\) service to .* successfully registered with NN",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool .* \(Datanode Uuid null\) service to .* beginning handshake with .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as .*:.* with total resource of <memory:.*, vCores:.*>",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode is OFF",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval .* milliseconds",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true",
"INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file .* \-> .*",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file .* size .* bytes.",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for .*",
"INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default\-rack/.*:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :\[\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application .* from user: .* activated in queue: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile\(file=.*, cpktTxId=.*\)",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt .* with final state: .*, and exit status: .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written = .*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode extension entered.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed \- appId: .* user: .* queue: .* #user\-pending\-applications: .* #user\-active\-applications: .* #queue\-pending\-applications: .* #queue\-active\-applications: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to .*:.*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode ON, in safe mode extension.",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master\-key for container\-tokens, got key with id .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for .*",
"INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node .*\(cmPort: .* httpPort: .*\) registered with capability: <memory:.*, vCores:.*>, assigned nodeId .*:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application .* from user: .*, in queue: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : file:.*",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started",
"INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: .* Total time for transactions\(ms\): .* Number of transactions batched in Syncs: .* Number of syncs: .* SyncTimes\(ms\): .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: .*/.*:.*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: registered UNIX signal handlers for \[TERM, HUP, INT\]",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: false",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.* }, \] for AM .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication = .*",
"INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web\-server for .* at: .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams = .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added \- appId: .* user: .*, leaf\-queue: default #user\-pending\-applications: .* #user\-active\-applications: .* #queue\-pending\-applications: .* #queue\-active\-applications: .*",
"INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine \(eg GC\): pause of approximately .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile\(file=.*, cpktTxId=.*\)",
"INFO org.apache.hadoop.http.HttpServer2: adding path spec: .*",
"INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter\(org.mortbay.log\) via .*",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication = .*",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started",
"INFO org.apache.hadoop.hdfs.StateChange: DIR\* completeFile: .* is closed by .*",
"INFO BlockStateChange: BLOCK\* processReport .*: from storage .* node DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=lv=.*;cid=.*;nsid=.*;c=.*\), blocks: .*, hasStaleStorage: .*, processing time: .* msecs",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent\-queue .* name=.*, fullname=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer = .*",
"INFO org.apache.hadoop.conf.Configuration: found resource .* at file:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup = .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master\-key for nm\-tokens",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use .*:.* to access this namenode/service.",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: false",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application .* requests cleared",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Perms after creating .*, Expected: .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension = .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> \(Datanode Uuid unassigned\) service to .*/.*:.* starting to offer service",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under\-replicated blocks = .*",
"INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed \- appId: .* user: .* leaf\-queue of parent: root #applications: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode .*/.*:.* using BLOCKREPORT_INTERVAL of .* CACHEREPORT_INTERVAL of .* Initial delay: .*; heartBeatInterval=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner = .* \(auth:SIMPLE\)",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=.*;bpid=.*;lv=.*;nsInfo=lv=.*;cid=.*;nsid=.*;c=.*;bpid=.*;dnuuid=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container .* succeeded",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /.*:.*, dest: /.*:.*, bytes: .*, op: .*, cliID: .*, offset: .*, srvID: .*, blockid: .*:.*, duration: .*",
"INFO BlockStateChange: BLOCK\* addToInvalidates: .* .*:.* .*:.* .*:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: .*, service: .*:.* }, \] for AM .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node .*:.* clusterResource: <memory:.*, vCores:.*>",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: .*:.*, type=.* terminating",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:.*, vCores:.*>>, maximumAllocation=<<memory:.*, vCores:.*>>, asynchronousScheduling=.*, asyncScheduleInterval=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://.*:.*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Safe mode ON.",
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled\? .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast\-forwarding stream '.*' to transaction ID .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment .*",
"INFO BlockStateChange: BLOCK\* addStoredBlock: blockMap updated: .*:.* is added to .* size .*",
"INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: .* metrics system started",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading .* INodes.",
"INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = .*",
"INFO BlockStateChange: BLOCK\* BlockManager: ask .*:.* to delete \[.*, .*, .*, .*, .*, .*\]",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done",
"INFO BlockStateChange: BLOCK\* BlockManager: ask .*:.* to delete \[.*\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: .*",
"INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' \(class=org.apache.hadoop.hdfs.web.AuthFilter\)",
"INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled\? .*",
"INFO org.mortbay.log: Started .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: .* unregistered successfully.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= .*, capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>usedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = .*,.*,.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: .*",
"INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache",
"INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: .* AttemptId: .* MasterContainer: Container: \[ContainerId: .*, NodeId: .*:.*, NodeHttpAddress: .*:.*, Resource: <memory:.*, vCores:.*>, Priority: .*, Token: Token { kind: ContainerToken, service: .*:.* }, \]",
"INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Explicitly setting permissions to : .*, .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.",
"INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG:",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=.*",
"WARN org.apache.hadoop.hdfs.server.common.Util: Path .* should be specified as a URI in configuration files. Please update hdfs configuration.",
"INFO org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system \[hdfs://.*:.*\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: \[.*\]",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryClientService: Instantiated HistoryClientService at .*/.*:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* IP=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.* APPATTEMPTID=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>, usedCapacity=.*, absoluteUsedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* IP=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.*",
"INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Initializing Existing Jobs...",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: .* and NMTokenKeyActivationDelay: .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: History Cleaner .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: .* and AMRMTokenKeyActivationDelay: .* ms",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default",
"INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=.*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip\-hostname\-check=.*",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with .* physical memory allocated to containers, which is more than .* of the total physical memory available \(.*\). Thrashing might happen.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken",
"WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Slow BlockReceiver write data to disk cost:.* \(threshold=.*\)",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG:",
#"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=.*, asboluteCapacity=.*, maxCapacity=.*, asboluteMaxCapacity=.*, state=.*, acls=.*, labels=*,",
"WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory \(dfs.namenode.name.dir\) configured. Beware of data loss due to lack of redundant storage directories!",
"INFO BlockStateChange: BLOCK\* ask .*:.* to replicate .* to datanode\(s\) .*:.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: .* and ContainerTokenKeyActivationDelay: .*",
"WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager\$ApplicationSummary: appId=.*,name=.*,user=.*,queue=.*,state=.*,trackingUrl=.*,appMasterHost=.*,startTime=.*,finishTime=.*,finalStatus=.*,memorySeconds=.*,vcoreSeconds=.*,preemptedAMContainers=.*,preemptedNonAMContainers=.*,preemptedResources=<memory:.*, vCores:.*>,applicationType=.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock .*:.* received exception org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block .*:.* already exists in state .* and thus cannot be created.",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: JobHistory Init",
"WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory \(dfs.namenode.edits.dir\) configured. Beware of data loss due to lack of redundant storage directories!",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting CheckDiskError Thread",
"INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=.*,submitTime=.*,launchTime=.*,firstMapTaskLaunchTime=.*,firstReduceTaskLaunchTime=.*,finishTime=.*,resourcesPerMap=.*,resourcesPerReduce=.*,numMaps=.*,numReduces=.*,user=.*,queue=.*,status=.*,mapSlotSeconds=.*,reduceSlotSeconds=.*,jobName=.*",
"INFO org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage: CachedHistoryStorage Init",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=lv=.*;cid=.*;nsid=.*;c=.*\) Starting thread to transfer .*:.* to .*:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK\* .*{UCState=.*, truncateBlock=.*, primaryNodeIndex=.*, replicas=.*, .*, .*} is not COMPLETE \(ucState = .*, replication# = .* < minimum = .*\) in file .*",
"INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: STARTUP_MSG:",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: .* sent to absent container .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : .*:.* for container : .*",
"INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop\-metrics2.properties",
"INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master\-key for container\-tokens, got key with id .*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Replication Queue initialization scan for invalid, over\- and under\-replicated blocks completed in .* msec",
"INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=.* min\(s\)",
"INFO org.apache.hadoop.util.GSet: VM type = .*",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= .*, capacity=.*, absoluteCapacity=.*, usedResources=<memory:.*, vCores:.*>usedCapacity=.*, numApps=.*, numContainers=.*",
"INFO org.apache.hadoop.hdfs.StateChange: STATE\* Network topology has .* racks and .* datanodes",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:.*",
"INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules",
"INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container .* : .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = .*",
"INFO org.apache.hadoop.yarn.util.RackResolver: Resolved .* to /default\-rack",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup",
"INFO org.apache.hadoop.yarn.webapp.View: Getting list of all Jobs.",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger :.* .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is .*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs",
"INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold\-pct = .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master\-key for .*",
"WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named .* in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of .*. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.",
"INFO org.apache.hadoop.hdfs.StateChange: BLOCK\* registerDatanode: from DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=lv=.*;cid=.*;nsid=.*;c=.*\) storage .*",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period :.* secs \(.* min\)",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration .*",
"INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts \(include/exclude\) list",
"INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner\(.*, .*\): no suitable block pools found to scan. Waiting .*",
"ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value below .* ms/sec. Assuming default value of .*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching .*",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode \[\]",
"INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=.* OPERATION=.* TARGET=.* RESULT=.* APPID=.*",
"INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG.*",
"INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file .* of size .* edits # .* loaded in .* seconds",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool .* on volume .*: .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container\-requests as container manager rpc server is still starting.",
"INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool .* on .*: .*",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Using .* threads to upgrade data directories \(dfs.datanode.parallel.volumes.load.threads.num=.*, dataDirs=.*\)",
"INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at .* with interval of .*",
"INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID .* for DN .*:.*",
"INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain .* images with txid >= .*",
"INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on .* acquired by nodename .*@.*",
"INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid .* to namenode at http://.*:.* in .* seconds",
"INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than .* times",
"INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool .* on volume .*",
"INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: .*, with delay of .* seconds",
"INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.",
"INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is .*",
"INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool .* Total blocks: .*, missing metadata files:.*, missing block files:.*, missing blocks in memory:.*, mismatched blocks:.*",
"INFO org.apache.hadoop.hdfs.server.datanode.DataNode: .*:.*:DataXceiver error processing .* operation src: /.*:.* dst: /.*:.*; org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block .*:.* already exists in state .* and thus cannot be created.",
"INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush",
"WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration\(.*:.*, datanodeUuid=.*, infoPort=.*, infoSecurePort=.*, ipcPort=.*, storageInfo=lv=.*;cid=.*;nsid=.*;c=.*\):Failed to transfer .*:.* to .*:.* got",
]

def remove_log_template_matches(logs, logtem):
    # Remove matching logs using pre-filled log templates
    for i in range(0,len(logtem)):
        log_template = logtem[i]
        # Remove any matched logs from the logs.
        before_removal = len(logs)
        alog = None
        for j in reversed(range(0,len(logs))):
            matched = re.match("^"+log_template+"$",logs[j])
            if matched!=None:
                alog = logs[j]
                del logs[j]
        removed_logs = before_removal - len(logs)

        if removed_logs==0:
            print "ERROR: no matching logs found from the given template."
            print "template:", log_template
            sys.exit(0)

        print "\033[0;34m"+"["+format(i,'3d')+"]",format(len(logs),'5d'),format(removed_logs,'4d'),"\033[0m","\033[0;35m\""+logtem[i]+"\",\033[0m"


def read_a_logfile(infile):
    logs = []

    lines = [line.rstrip() for line in infile]
    for log in lines:
        if len(log.strip())==0:
            continue
        log = " ".join(log.split())
        logs.append(log)

    print "Total number of logs loaded:",len(logs)
    return logs


if __name__ == '__main__':

    global new_pattern_added

    try:
        parser = argparse.ArgumentParser(description="")
        parser.add_argument('--logfile', type=argparse.FileType('r'), required=True, help='One logfile name.')

        args = parser.parse_args()
        input_logfile = args.logfile

    except Exception, e:
        print('Error: %s' % str(e))

    print "Loading all logs into memory."
    raw_logs = read_a_logfile(input_logfile)

    loaded_log_count = len(raw_logs)
    remove_log_template_matches(raw_logs, prepopulated_log_templates)
    print "Loaded Log count:", loaded_log_count
    print "Remaining Log count:",len(raw_logs)
    print "Prepopulated log template count:", len(prepopulated_log_templates)

    #for i in range(0,len(raw_logs)):
    #    print raw_logs[i]

    log_templates = []
    for t in prepopulated_log_templates:
        log_templates.append({"count":1,"template":t}) 
    pickle.dump(log_templates,open("TMP1029348.bin","wb"))

